# Word embeddings.
dummy {
  path = ""
  size = 0
  format = txt
  lowercase = false
}

glove_300d {
  path = glove.840B.300d.txt
  size = 300
  format = txt
  lowercase = false
}

glove_300d_filtered {
  path = glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}

glove_300d_v5_filtered {
  path = glove.840B.300d.txt.v5.filtered
  size = 300
  format = txt
  lowercase = false
}

turian_50d {
  path = turian.50d.txt
  size = 50
  format = txt
  lowercase = false
}

glove_300d_2w {
  path = glove_50_300_2.txt
  size = 300
  format = txt
  lowercase = false
}

glove_300d_5w {
  path = glove_50_300_5.txt
  size = 300
  format = txt
  lowercase = false
}

glove_300d_10w {
  path = glove_50_300_10.txt
  size = 300
  format = txt
  lowercase = false
}

# Main configuration.
best {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  top_span_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "char_vocab.english.txt"
  context_embeddings = ${glove_300d_filtered}
  head_embeddings = ${glove_300d_2w}
  contextualizer = lstm
  contextualization_size = 200
  contextualization_layers = 3
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  model_heads = true
  lm_path = "elmo/english.lm_embeddings.skip.hdf5"
  lm_layers = 3
  lm_size = 1024
  sva = false

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100
  const_weight = 0  # 0.1
  ner_weight = 0  # 0.1

  # Other.
  train_path = train.english.jsonlines
  eval_path = dev.english.jsonlines
  conll_eval_path = dev.english.v4_gold_conll
  genres = ["bc", "bn", "mz", "nw", "pt", "tc", "wb"]
  const_labels = ["PRT", "WHADJP", "PP", "UCP", "WHPP", "NX", "PRN", "RRC", "WHADVP", "SINV", "SBAR", "META", "LST", "ADJP", "EMBED", "NAC", "QP", "NML", "SQ", "WHNP", "FRAG", "TOP", "SBARQ", "CONJP", "INTJ", "S", "VP", "NP", "X", "ADVP"]
  ner_labels = ["ORDINAL", "LOC", "PRODUCT", "NORP", "WORK_OF_ART", "LANGUAGE", "PERCENT", "GPE", "TIME", "MONEY", "PERSON", "CARDINAL", "ORG", "DATE", "FAC", "LAW", "EVENT", "QUANTITY"]
  eval_frequency = 1000
  report_frequency = 250
  log_root = logs
  eval_sleep_secs = 600
}

mtl_best = ${best} {
  char_embedding_size = 8
  contextualization_layers = 3
  contextualization_size = 200

  use_features = true
  use_metadata = true
  model_heads = true
  task_heads = false

  max_arg_width = 30
  argument_ratio = 0.8
  predicate_ratio = 0.4
  mention_ratio = 0.4

  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  num_attention_heads = 1
  span_score_weight = 0.0

  eval_sleep_secs = 1200

  srl_labels = ["R-ARGM-COM", "C-ARGM-NEG", "C-ARGM-TMP", "R-ARGM-DIR", "ARGM-LOC", "R-ARG2", "ARGM-GOL", "ARG5", "ARGM-EXT", "R-ARGM-ADV", "C-ARGM-MNR", "ARGA", "C-ARG4", "C-ARG2", "C-ARG3", "C-ARG0", "C-ARG1", "ARGM-ADV", "ARGM-NEG", "R-ARGM-MNR", "C-ARGM-EXT", "R-ARGM-PRP", "C-ARGM-ADV", "R-ARGM-MOD", "C-ARGM-ADJ", "ARGM-LVB", "R-ARGM-PRD", "ARGM-MNR", "ARGM-ADJ", "C-ARGM-CAU", "ARGM-CAU", "C-ARGM-MOD", "R-ARGM-EXT", "C-ARGM-COM", "ARGM-COM", "R-ARGM-GOL", "R-ARGM-TMP", "R-ARG4", "ARGM-MOD", "R-ARG1", "R-ARG0", "R-ARG3", "V", "ARGM-REC", "C-ARGM-DSP", "R-ARG5", "ARGM-DIS", "ARGM-DIR", "R-ARGM-LOC", "C-ARGM-DIS", "ARG0", "ARG1", "ARG2", "ARG3", "ARG4", "ARGM-TMP", "C-ARGM-DIR", "ARGM-PRD", "R-ARGM-PNC", "ARGM-PRX", "ARGM-PRR", "R-ARGM-CAU", "C-ARGM-LOC", "ARGM-PNC", "ARGM-PRP", "C-ARGM-PRP", "ARGM-DSP"]  

  coref_loss = "mention_rank"
  enforce_srl_constraint = false
  filter_v_args = true
  use_gold_predicates = false
  srl_weight = 1.0
  ner_weight = 1.0
  coref_weight = 1.0
  const_weight = 0.0

  batch_size = 40
  max_tokens_per_batch = 700

  # Updated dataset.
  train_path = train.english.mtl.jsonlines
  eval_path = dev.english.mtl.jsonlines
  lm_path = "elmo/english.lm_embeddings.skip.hdf5"
  lm_layers = 3
  lm_size = 1024
  main_metrics = srl_coref_ner

  srl_conll_eval_path = ""
  ner_conll_eval_path = "dev.conll2012.ner.gold.iob2"
}

mtl_balance = ${mtl_best} {
  ner_weight = 0.33
  srl_weight = 0.33
  coref_weight = 0.33
  batch_size = 35
  max_tokens_per_batch = 600
}

mtl_balance_noelmo = ${mtl_balance} {
  lm_path = ""
}


# CoNLL2012

conll2012_best = ${mtl_best} {
  srl_weight = 1.0
  coref_weight = 0.0
  ner_weight = 0.0
  const_weight = 0.0
  main_metrics = srl
  ner_conll_eval_path = ""

  include_c_v = false
}

conll2012_noelmo = ${conll2012_best} {
  lm_path = ""
  lm_path_dev = ""
}

conll2012_final = ${conll2012_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = "test.english.mtl.jsonlines"
  #eval_path = "conll12test.english.v5.jsonlines"
  lm_path_dev = "https://tfhub.dev/google/elmo/1"
  #lm_path_dev = "elmo/ontonotes5.test.english.lm_embeddings.skip.hdf5"
  srl_conll_eval_path = ""
}

conll2012_noelmo_final = ${conll2012_final} {
  lm_path = ""
  lm_path_dev = ""
}

conll2012_goldprops = ${conll2012_best} {
  # Using larger train and dev split following previous work.
  train_path = train.english.v5.jsonlines
  eval_path = dev.english.v5.jsonlines
  context_embeddings = ${glove_300d_v5_filtered}
  lm_path = "elmo/ontonotes5.train.english.lm_embeddings.skip.hdf5"
  lm_path_dev = "elmo/ontonotes5.dev.english.lm_embeddings.skip.hdf5"
  use_gold_predicates = true
}

conll2012_goldprops_final = ${conll2012_goldprops} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = test.english.mtl.jsonlines
  lm_path_dev = "https://tfhub.dev/google/elmo/1"
  #lm_path_dev = "elmo/ontonotes5.test.english.lm_embeddings.skip.hdf5"
}

conll2012_goldprops_noelmo = ${conll2012_goldprops} {
  lm_path = ""
  lm_path_dev = ""
}

conll2012_goldprops_noelmo_final = ${conll2012_goldprops_final} {
  lm_path = ""
  lm_path_dev = ""
}

# CoNLL-05 Experiments.

conll05_best = ${conll2012_best} {
  ner_labels = ["ORG", "MISC", "PER", "LOC"]
  srl_labels = ["R-A4", "C-AM-DIR", "R-A0", "R-A1", "AM-MNR", "R-A3", "V", "C-AM-MNR", "R-AM-MNR", "R-AM-TMP", "AM-PRD", "R-AM-DIR", "C-AM-CAU", "R-A2", "C-AM-TMP", "AM-EXT", "R-AM-CAU", "A1", "A0", "A3", "A2", "A5", "A4", "R-AM-EXT", "C-V", "AM-DIR", "AM-DIS", "AM-TMP", "AM-REC", "AA", "C-AM-DIS", "AM-TM", "AM-PNC", "AM-LOC", "C-A4", "AM", "R-AM-LOC", "C-AM-EXT", "AM-MOD", "AM-CAU", "C-AM-LOC", "R-AM-ADV", "C-AM-PNC", "C-AM-NEG", "C-A3", "C-A2", "C-A1", "C-A0", "R-AA", "C-A5", "R-AM-PNC", "AM-ADV", "C-AM-ADV", "AM-NEG"]
  const_labels = ["NAC", "SBAR", "SINV", "ADJP", "S1", "CONJP", "PP", "PRT", "PRN", "RRC", "NX", "WHPP", "LST", "NP", "WHADVP", "FRAG", "INTJ", "VP", "SBARQ", "X", "ADVP", "QP", "SQ", "UCP", "S", "WHADJP", "WHNP"]

  train_path = train.english.conll05.jsonlines
  eval_path = dev.english.conll05.jsonlines
  srl_conll_eval_path = "./data/srl/conll05.devel.props.gold.txt"

  lm_path = "./elmo/conll05.train.elmo_embeddings.hdf5"
  lm_path_dev = "./elmo/conll05.dev.elmo_embeddings.hdf5"
}

conll05_goldprops = ${conll05_best} {
  use_gold_predicates = true
}

conll05_noelmo = ${conll05_best} {
  lm_path = ""
  lm_path_dev = ""
}

conll05_goldprops_noelmo = ${conll05_best} {
  use_gold_predicates = true
  include_c_v = true  # Due to historical reasons.
  lm_path = ""
  lm_path_dev = ""
}

conll05_final_wsj = ${conll05_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = "test_wsj.conll05.sanitized.jsonlines"
  #eval_path = "test_wsj.english.conll05.jsonlines"
  srl_conll_eval_path = "data/srl/conll05.test.wsj.props.gold.txt"
  #lm_path_dev = "elmo/conll05.test_wsj.elmo_embeddings.hdf5"
  lm_path_dev = "https://tfhub.dev/google/elmo/1"
}

conll05_final_brown = ${conll05_final_wsj} {
  eval_path = "test_brown.conll05.sanitized.jsonlines"
  #eval_path = "test_brown.english.conll05.jsonlines"
  srl_conll_eval_path = "data/srl/conll05.test.brown.props.gold.txt"
  #lm_path_dev = "elmo/conll05.test_brown.elmo_embeddings.hdf5"
  lm_path_dev = "https://tfhub.dev/google/elmo/1"
}

conll05_noelmo_final_wsj = ${conll05_final_wsj} {
  lm_path = ""
}

conll05_noelmo_final_brown = ${conll05_final_brown} {
  lm_path = ""
}

conll05_goldprops_final_wsj = ${conll05_final_wsj} {
  eval_path = "test_wsj.conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}

conll05_goldprops_final_brown = ${conll05_final_brown} {
  eval_path = "test_brown.conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}

conll05_goldprops_noelmo_final_wsj = ${conll05_final_wsj} {
  lm_path = ""
  lm_path_dev = ""
  eval_path = "test_wsj.conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
  include_c_v = true  # Due to historical reasons.
}

conll05_goldprops_noelmo_final_brown = ${conll05_final_brown} {
  lm_path = ""
  lm_path_dev = ""
  eval_path = "test_brown.conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
  include_c_v = true  # Due to historical reasons.
}



