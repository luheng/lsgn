# Word embeddings.
dummy {
  path = ""
  size = 0
  format = txt
  lowercase = false
}

glove_300d {
  path = glove.840B.300d.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_filtered {
  path = glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}

glove_300d_v5_filtered {
  path = glove.840B.300d.txt.v5.filtered
  size = 300
  format = txt
  lowercase = false
}
turian_50d {
  path = turian.50d.txt
  size = 50
  format = txt
  lowercase = false
}
glove_300d_2w {
  path = glove_50_300_2.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_5w {
  path = glove_50_300_5.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_10w {
  path = glove_50_300_10.txt
  size = 300
  format = txt
  lowercase = false
}
symmetric_300d {
  path = sp_sg_gw_300.txt
  size = 300
  format = txt
  lowercase = false
}
wiki_arabic_300d {
  path = wiki.ar.vec
  size = 300
  format = vec
  lowercase = false
}
wiki_chinese_300d {
  path = wiki.zh.vec
  size = 300
  format = vec
  lowercase = false
}

# Compute clusters.
nlp {
  addresses {
    ps = [nlp2:2222]
    worker = [n01:2222, n02:2222, n03:2222, n04:2222, n05:2222, n06:2222, n07:2222, n08:2222, n09:2222, n10:2222, n11:2222, n12:2222, n13:2222, n14:2222, n15:2222, n16:2222]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
}
nlp_a {
  addresses {
    ps = [nlp2:2222]
    worker = [n01:2222, n02:2222, n03:2222, n04:2222, n05:2222, n06:2222, n07:2222, n08:2222]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1]
}
nlp_b {
  addresses {
    ps = [nlp2:3333]
    worker = [n09:3333, n10:3333, n11:3333, n12:3333, n13:3333, n14:3333, n15:3333, n16:3333]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1]
}
appositive {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [0, 1]
}
majestix {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [0, 2]
}
framling {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [1, 2]
}


# Main configuration.
best {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  top_span_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "char_vocab.english.txt"
  context_embeddings = ${glove_300d_filtered}
  head_embeddings = ${glove_300d_2w}
  #head_embeddings = ${dummy}
  contextualizer = lstm
  contextualization_size = 200
  contextualization_layers = 3
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  model_heads = true
  lm_path = "elmo/english.lm_embeddings.skip.hdf5"
  lm_layers = 3
  lm_size = 1024
  sva = false

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100
  const_weight = 0  # 0.1
  ner_weight = 0  # 0.1

  # Other.
  train_path = train.english.jsonlines
  eval_path = dev.english.jsonlines
  conll_eval_path = dev.english.v4_gold_conll
  genres = ["bc", "bn", "mz", "nw", "pt", "tc", "wb"]
  const_labels = ["PRT", "WHADJP", "PP", "UCP", "WHPP", "NX", "PRN", "RRC", "WHADVP", "SINV", "SBAR", "META", "LST", "ADJP", "EMBED", "NAC", "QP", "NML", "SQ", "WHNP", "FRAG", "TOP", "SBARQ", "CONJP", "INTJ", "S", "VP", "NP", "X", "ADVP"]
  ner_labels = ["ORDINAL", "LOC", "PRODUCT", "NORP", "WORK_OF_ART", "LANGUAGE", "PERCENT", "GPE", "TIME", "MONEY", "PERSON", "CARDINAL", "ORG", "DATE", "FAC", "LAW", "EVENT", "QUANTITY"]
  eval_frequency = 1000
  report_frequency = 250
  log_root = logs
  cluster = ${appositive}
  #cluster = ${majestix}
  #cluster = ${nlp}
  eval_sleep_secs = 600
}

debug = ${best} {
  max_antecedents = 100
  max_training_sentences = 40
  filter_widths = [5]
  filter_size = 100
  char_embedding_size = 32
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  contextualization_size = 50
  contextualization_layers = 1
  ffnn_size = 50
  max_span_width = 10
  lm_path = ""
  train_path = dev.english.jsonlines
  eval_frequency = 100
  report_frequency = 5
  log_root = /tmp/debug
}

# Multiple full models for ensembling.
best0 = ${best}
best1 = ${best}
best2 = ${best}
best3 = ${best}
best4 = ${best}

# Ablations.
glove = ${best} {
  embeddings = [${glove_300d_filtered}]
}
turian = ${best} {
  embeddings = [${turian_50d}]
}
nochar = ${best} {
  char_embedding_size = -1
}
nometa = ${best} {
  use_metadata = false
}
noheads = ${best} {
  model_heads = false
}
nofeatures = ${best} {
  use_features = false
}

# For evaluation. Do not use for training (i.e. only for decoder.py, ensembler.py, visualize.py and demo.py). Rename `best0` directory to `final`.
final = ${best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = test.english.jsonlines
  const_weight = 0
  ner_weight = 0
  conll_eval_path = dev.english.v4_gold_conll
}

mtl_best = ${best} {
  char_embedding_size = 8
  contextualization_layers = 3
  contextualization_size = 200

  use_features = true
  use_metadata = true
  model_heads = true
  task_heads = false

  max_arg_width = 30
  argument_ratio = 0.8
  predicate_ratio = 0.4
  mention_ratio = 0.4

  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  srl_weight = 1.0
  ner_weight = 0.0
  const_weight = 0.0
  num_attention_heads = 1
  span_score_weight = 0.0

  eval_sleep_secs = 1200

  srl_labels = ["R-ARGM-COM", "C-ARGM-NEG", "C-ARGM-TMP", "R-ARGM-DIR", "ARGM-LOC", "R-ARG2", "ARGM-GOL", "ARG5", "ARGM-EXT", "R-ARGM-ADV", "C-ARGM-MNR", "ARGA", "C-ARG4", "C-ARG2", "C-ARG3", "C-ARG0", "C-ARG1", "ARGM-ADV", "ARGM-NEG", "R-ARGM-MNR", "C-ARGM-EXT", "R-ARGM-PRP", "C-ARGM-ADV", "R-ARGM-MOD", "C-ARGM-ADJ", "ARGM-LVB", "R-ARGM-PRD", "ARGM-MNR", "ARGM-ADJ", "C-ARGM-CAU", "ARGM-CAU", "C-ARGM-MOD", "R-ARGM-EXT", "C-ARGM-COM", "ARGM-COM", "R-ARGM-GOL", "R-ARGM-TMP", "R-ARG4", "ARGM-MOD", "R-ARG1", "R-ARG0", "R-ARG3", "V", "ARGM-REC", "C-ARGM-DSP", "R-ARG5", "ARGM-DIS", "ARGM-DIR", "R-ARGM-LOC", "C-ARGM-DIS", "ARG0", "ARG1", "ARG2", "ARG3", "ARG4", "ARGM-TMP", "C-ARGM-DIR", "ARGM-PRD", "R-ARGM-PNC", "ARGM-PRX", "ARGM-PRR", "R-ARGM-CAU", "C-ARGM-LOC", "ARGM-PNC", "ARGM-PRP", "C-ARGM-PRP", "ARGM-DSP"]  

  span_score_weight = 0.0
  coref_loss = "mention_rank"
  enforce_srl_constraint = False
  filter_v_args = true
  refresh_srl_scores = false
  refresh_antecedent_scores = false
  weight_loss_by_uncertainty = false

  use_gold_predicates = false
  srl_weight = 1.0
  ner_weight = 1.0
  coref_weight = 1.0
  const_weight = 0.0

  batch_size = 40
  max_tokens_per_batch = 700

  # Updated dataset.
  train_path = train.english.mtl.jsonlines
  eval_path = dev.english.mtl.jsonlines
  lm_path = "elmo/english.lm_embeddings.skip.hdf5"
  lm_layers = 3
  lm_size = 1024
  main_metrics = srl_coref_ner

  srl_conll_eval_path = ""
  ner_conll_eval_path = "dev.conll2012.ner.gold.iob2"
}

mtl_reweight = ${mtl_best} {
  ner_weight = 0.4
  srl_weight = 0.2
  coref_weight = 0.4
  max_tokens_per_batch = 600
}

mtl_balance = ${mtl_best} {
  ner_weight = 0.33
  srl_weight = 0.33
  coref_weight = 0.33
  batch_size = 35
  max_tokens_per_batch = 600
}

mtl_balance_noelmo_final = ${mtl_balance} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = "test.english.mtl.jsonlines"
  conll_eval_path = test.english.v4_gold_conll
  ner_conll_eval_path = "test.conll2012.ner.gold.iob2"
  lm_path = ""
}

mtl_new_balance = ${mtl_balance} {
  new_srl_features = true
  projection = "up"
  use_gold_predicates = false
  batch_size = 32
  max_tokens_per_batch = 500
}

mtl_balance_noelmo = ${mtl_balance} {
  lm_path = ""
}

coref_best = ${mtl_best} {
  coref_weight = 1.0
  srl_weight = 0
  ner_weight = 0
  main_metrics = coref
}

coref_best_final = ${coref_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
}

coref_noelmo = ${coref_best} {
  lm_path = ""
}

coref_noelmo_final = ${coref_best_final} {
  lm_path = ""
}

ner_best = ${mtl_best} {
  coref_weight = 0.0
  srl_weight = 0.0
  ner_weight = 1.0
  main_metrics = ner
}

ner_noelmo = ${ner_best} {
  lm_path = ""
}

ner_nohead = ${ner_noelmo} {
  model_heads = false
}

ner_nochar = ${ner_noelmo} {
  char_embedding_size = -1
}

ner_shallow_lstm = ${ner_noelmo} {
  contextualization_layers = 1
}

ner_shallow_ffnn = ${ner_noelmo} {
  ffnn_depth = 1
}

ner_w10 = ${ner_noelmo} {
  max_arg_width = 10
}

ner_noglove = ${ner_noelmo} {
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
}

ner_best_final = ${ner_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
}

ner_noelmo_final = ${ner_best_final} {
  lm_path = ""
  lm_path_dev = ""
  eval_path = test.mtl.sanitized.jsonlines
  ner_conll_eval_path = test.conll2012.ner.gold.iob2
}

coref_mention_classifier = ${coref_best} {
  coref_loss = "mention_classifier"
}

srl_best = ${mtl_best} {
  coref_weight = 0
  ner_weight = 0
  srl_weight = 1.0
  main_metrics = srl
}

srl_noelmo = ${srl_best} {
  lm_path = ""
}

srl_best_final = ${srl_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = "test.english.mtl.jsonlines"
  srl_conll_eval_path = ""
}

srl_noelmo_final = ${srl_best_final} {
  lm_path = ""
}

conll05_best = ${srl_best} {
  ner_labels = ["ORG", "MISC", "PER", "LOC"]
  srl_labels = ["R-A4", "C-AM-DIR", "R-A0", "R-A1", "AM-MNR", "R-A3", "V", "C-AM-MNR", "R-AM-MNR", "R-AM-TMP", "AM-PRD", "R-AM-DIR", "C-AM-CAU", "R-A2", "C-AM-TMP", "AM-EXT", "R-AM-CAU", "A1", "A0", "A3", "A2", "A5", "A4", "R-AM-EXT", "C-V", "AM-DIR", "AM-DIS", "AM-TMP", "AM-REC", "AA", "C-AM-DIS", "AM-TM", "AM-PNC", "AM-LOC", "C-A4", "AM", "R-AM-LOC", "C-AM-EXT", "AM-MOD", "AM-CAU", "C-AM-LOC", "R-AM-ADV", "C-AM-PNC", "C-AM-NEG", "C-A3", "C-A2", "C-A1", "C-A0", "R-AA", "C-A5", "R-AM-PNC", "AM-ADV", "C-AM-ADV", "AM-NEG"]
  const_labels = ["NAC", "SBAR", "SINV", "ADJP", "S1", "CONJP", "PP", "PRT", "PRN", "RRC", "NX", "WHPP", "LST", "NP", "WHADVP", "FRAG", "INTJ", "VP", "SBARQ", "X", "ADVP", "QP", "SQ", "UCP", "S", "WHADJP", "WHNP"]

  train_path = train.english.conll05.jsonlines
  eval_path = dev.english.conll05.jsonlines
  srl_conll_eval_path = "./data/srl/conll05.devel.props.gold.txt"

  lm_path = "./elmo/conll05.train.elmo_embeddings.hdf5"
  lm_path_dev = "./elmo/conll05.dev.elmo_embeddings.hdf5"
}

conll05_goldprops = ${conll05_best} {
  use_gold_predicates = true
}

conll05_goldprops_fix = ${conll05_goldprops}

conll05_final_wsj = ${conll05_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  #eval_path = "test_wsj.conll05.sanitized.jsonlines"
  #eval_path = "test_wsj.english.conll05.jsonlines"
  #srl_conll_eval_path = "data/srl/conll05.test.wsj.props.gold.txt"
  #lm_path_dev = "elmo/conll05.test_wsj.elmo_embeddings.hdf5"
}


conll05_final_brown = ${conll05_final_wsj} {
  #eval_path = "test_brown.conll05.sanitized.jsonlines"
  eval_path = "test_brown.english.conll05.jsonlines"
  srl_conll_eval_path = "data/srl/conll05.test.brown.props.gold.txt"
  lm_path_dev = "elmo/conll05.test_brown.elmo_embeddings.hdf5"
}

conll05_goldprops_final_wsj = ${conll05_final_wsj} {
  eval_path = "test.wsj_conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}

conll05_goldprops_final_brown = ${conll05_final_brown} {
  eval_path = "test.brown_conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}


conll05_goldprops_noelmo = ${conll05_goldprops} {
  use_gold_predicates = true
  lm_path = ""
}

conll05_goldprops_noelmo_fix = ${conll05_goldprops_noelmo}

conll05_goldprops_noelmo_final_wsj = ${conll05_final_wsj} {
  lm_path = ""
  eval_path = "test.wsj_conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}

conll05_goldprops_noelmo_final_brown = ${conll05_final_brown} {
  lm_path = ""
  eval_path = "test.brown_conll05.sanitized.goldprops.jsonlines"
  use_gold_predicates = true
}

conll05_noelmo = ${conll05_best} {
  lm_path = ""
}

conll05_noelmo_final_wsj = ${conll05_final_wsj} {
  lm_path = ""
  eval_path = "test_wsj.english.conll05.jsonlines"
  use_gold_predicates = false
}

conll05_noelmo_final_brown = ${conll05_final_brown} {
  lm_path = ""
  eval_path = "test_brown.english.conll05.jsonlines"
  use_gold_predicates = false
}

conll05_new_goldprops_noelmo = ${conll05_noelmo} {
  lm_path = ""
  new_srl_features = true
  projection = "up"
  use_gold_predicates = true
}

conll05_new_goldprops = ${conll05_goldprops} {
  new_srl_features = true
  projection = "up"
  use_gold_predicates = true
}

conll05_new_noelmo = ${conll05_noelmo} {
  lm_path = ""
  new_srl_features = true
  projection = "up"
  use_gold_predicates = false
}

conll05_new = ${conll05_best} {
  new_srl_features = true
  projection = "up"
  use_gold_predicates = false
}
 


conll2012_best = ${srl_best} {
  ner_labels = ["ORDINAL", "LOC", "PRODUCT", "NORP", "WORK_OF_ART", "LANGUAGE", "PERCENT", "GPE", "TIME", "MONEY", "PERSON", "CARDINAL", "ORG", "DATE", "FAC", "LAW", "EVENT", "QUANTITY"]
  srl_labels = ["R-ARGM-COM", "C-ARGM-NEG", "C-ARGM-TMP", "R-ARGM-DIR", "ARGM-LOC", "R-ARG2", "ARGM-GOL", "ARG5", "ARGM-EXT", "R-ARGM-ADV", "C-ARGM-MNR", "ARGA", "C-ARG4", "C-ARG2", "C-ARG3", "C-ARG0", "C-ARG1", "ARGM-ADV", "ARGM-NEG", "R-ARGM-MNR", "C-ARGM-EXT", "R-ARGM-PRP", "C-ARGM-ADV", "R-ARGM-MOD", "C-ARGM-ADJ", "ARGM-LVB", "R-ARGM-PRD", "ARGM-MNR", "ARGM-ADJ", "C-ARGM-CAU", "ARGM-CAU", "C-ARGM-MOD", "R-ARGM-EXT", "C-ARGM-COM", "ARGM-COM", "R-ARGM-GOL", "R-ARGM-TMP", "R-ARG4", "ARGM-MOD", "R-ARG1", "R-ARG0", "R-ARG3", "V", "ARGM-REC", "C-ARGM-DSP", "R-ARG5", "ARGM-DIS", "ARGM-DIR", "R-ARGM-LOC", "C-ARGM-DIS", "ARG0", "ARG1", "ARG2", "ARG3", "ARG4", "ARGM-TMP", "C-ARGM-DIR", "ARGM-PRD", "R-ARGM-PNC", "ARGM-PRX", "ARGM-PRR", "R-ARGM-CAU", "C-ARGM-LOC", "ARGM-PNC", "ARGM-PRP", "C-ARGM-PRP", "ARGM-DSP"]
  const_labels = ["NAC", "SBAR", "SINV", "ADJP", "TOP", "CONJP", "META", "PP", "UCP", "PRN", "RRC", "NX", "WHPP", "LST", "NP", "WHADVP", "FRAG", "INTJ", "VP", "SBARQ", "PRT", "X", "EMBED", "ADVP", "QP", "SQ", "S", "WHADJP", "WHNP", "NML"]

  train_path = train.english.v5.jsonlines
  eval_path = dev.english.v5.jsonlines
  srl_conll_eval_path = "" #"./data/srl/conll2012.devel.props.gold.txt"

  lm_path = "elmo/ontonotes5.train.english.lm_embeddings.skip.hdf5"
  lm_path_dev = "elmo/ontonotes5.dev.english.lm_embeddings.skip.hdf5"

  context_embeddings = ${glove_300d_v5_filtered}
}

conll2012_noelmo = ${conll2012_best} {
  lm_path = ""
  lm_path_dev = ""
}

conll2012_noelmo_final = ${conll2012_noelmo} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = conll12test.english.v5.jsonlines
  #eval_path = dev.english.v5.jsonlines
}

conll2012_best_final = ${conll2012_best} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = conll12test.english.v5.jsonlines
  #eval_path = dev.english.v5.jsonlines
  lm_path_dev = "elmo/ontonotes5.test.english.lm_embeddings.skip.hdf5"
}

# This should be comparable to the ELMO result.
conll2012_goldprops = ${conll2012_best} {
  use_gold_predicates = true
}

conll2012_goldprops_fix = ${conll2012_goldprops}

conll2012_goldprops_embfix = ${conll2012_goldprops} {
  context_embeddings = ${glove_300d_v5_filtered}
}

conll2012_goldprops_final = ${conll2012_goldprops} {
  context_embeddings = ${glove_300d}
  head_embeddings = ${glove_300d_2w}
  eval_path = test.english.v5.jsonlines
  lm_path_dev = "elmo/ontonotes5.test.english.lm_embeddings.skip.hdf5"
  srl_conll_eval_path = ""
}

conll2012_goldprops_noelmo = ${conll2012_goldprops} {
  lm_path = ""
}

conll2012_goldprops_noelmo_fix = ${conll2012_goldprops_noelmo}

conll2012_goldprops_noelmo_embfix = ${conll2012_goldprops_noelmo} {
  context_embeddings = ${glove_300d_v5_filtered}
}

conll2012_wide_goldprops_noelmo = ${conll2012_goldprops} {
  lm_path = ""
  new_srl_features = true
  projection = "up"
  ffnn_size = 300
} 

conll2012_new_goldprops = ${conll2012_goldprops} {
  use_gold_predicates = true
  new_srl_features = true
  projection = "up"
}

conll2012_new_goldprops_noelmo = ${conll2012_goldprops_noelmo} {
  lm_path = ""
  use_gold_predicates = true
  new_srl_features = true
  projection = "up"
}

conll2012_goldprops_fix_final = ${conll2012_goldprops_final} {
  #new_srl_features = true
  #projection = "up"
  #lm_path = ""
  lm_path_dev = "elmo/ontonotes5.test.english.lm_embeddings.skip.hdf5"
  eval_path = conll12test.english.v5.jsonlines
}

chinese = ${best} {
  max_antecedents = 150
  max_training_sentences = 40
  char_vocab_path = "char_vocab.chinese.txt"
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  filter_widths = [1, 2, 3, 4]
  filter_size = 100
  char_embedding_size = 32
  lm_path = ""
  train_path = train.chinese.jsonlines
  eval_path = dev.chinese.jsonlines
  conll_eval_path = dev.chinese.v4_gold_conll
  const_labels = ["PP", "MBD", "UCP", "SKIP", "PRN", "NP", "DP", "FLR", "VCP", "ADJP", "DNP", "LCP", "TOP", "LST", "OTH", "QP", "FRAG", "VNV", "VSB", "INC", "DVP", "VRD", "VCD", "IP", "INTJ", "VPT", "VP", "DFL", "CP", "CLP", "ADVP"]
  log_root = chinese_logs
}

srl_chinese = ${srl_best} {
  char_vocab_path = "char_vocab.chinese.txt"
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  filter_widths = [1, 2, 3, 4]
  filter_size = 100
  char_embedding_size = 32
  lm_path = ""
  eval_sleep_secs = 600
  train_path = train.chinese.jsonlines
  eval_path = dev.chinese.jsonlines
}

srl_chinese2 = ${srl_chinese} {
  argument_ratio = 1.0
  predicate_ratio = 0.5
}

srl_chinese_goldprop = ${srl_chinese} {
  use_gold_predicates = true
}

arabic = ${best} {
  char_vocab_path = "char_vocab.arabic.txt"
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  filter_widths = [6]
  filter_size = 300
  lm_path = ""
  train_path = train.arabic.jsonlines
  eval_path = dev.arabic.jsonlines
  conll_eval_path = dev.arabic.v4_gold_conll
  const_labels = ["PRT", "LST", "UCP", "WHPP", "PRN", "NP", "WHADVP", "SBAR", "PP", "ADJP", "NAC", "SQ", "WHNP", "FRAG", "TOP", "SBARQ", "CONJP", "INTJ", "S", "VP", "X", "ADVP"]
  log_root = arabic_logs
}

lm_skip = ${best}

sgd = ${best} {
  optimizer = sgd
  learning_rate = 0.2
}

srl_arabic2 = ${srl_best} {
  char_vocab_path = "char_vocab.arabic.txt"
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  filter_widths = [6]
  filter_size = 600
  char_embedding_size = 8
  argument_ratio = 1.0
  batch_size = 10
  eval_sleep_secs = 600
  train_path = train.arabic.jsonlines
  eval_path = dev.arabic.jsonlines
}

srl_arabic_arg15 = ${srl_arabic2} {
  argument_ratio = 1.5
  predicate_ratio = 0.3
}

srl_arabic2 = ${srl_best} {
  char_vocab_path = "char_vocab.arabic.txt"
  context_embeddings = ${dummy}
  head_embeddings = ${dummy}
  filter_widths = [6]
  filter_size = 600
  char_embedding_size = 8
  argument_ratio = 1.0
  batch_size = 10
  eval_sleep_secs = 600
  train_path = train.arabic.jsonlines
  eval_path = dev.arabic.jsonlines
}

srl_arabic_arg15 = ${srl_arabic2} {
  argument_ratio = 1.5
  predicate_ratio = 0.3
}
